{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "italian-vintage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version 1.5.1+cu101\n",
      "Numpy Version 1.18.5 \n",
      "\n",
      "tensor([[ 73.,  67.,  43.],\n",
      "        [ 91.,  88.,  64.],\n",
      "        [ 87., 134.,  58.],\n",
      "        [102.,  43.,  37.],\n",
      "        [ 69.,  96.,  70.]])\n",
      "tensor([[ 56.,  70.],\n",
      "        [ 81., 101.],\n",
      "        [119., 133.],\n",
      "        [ 22.,  37.],\n",
      "        [103., 119.]]) \n",
      "\n",
      "tensor([[102.,  43.,  37.],\n",
      "        [ 91.,  88.,  64.],\n",
      "        [ 73.,  67.,  43.]])\n",
      "tensor([[ 22.,  37.],\n",
      "        [ 81., 101.],\n",
      "        [ 56.,  70.]]) \n",
      "\n",
      "Parameter containing:\n",
      "tensor([[-0.0114,  0.4578, -0.0512],\n",
      "        [ 0.1528, -0.1745, -0.1135]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.5516, -0.3824], requires_grad=True) \n",
      "\n",
      "Loss improved from inf to 7117.82\n",
      "Loss improved from 7117.82 to 4780.08\n",
      "Loss improved from 4780.08 to 3116.22\n",
      "Loss improved from 3116.22 to 2983.52\n",
      "Loss improved from 2983.52 to 1676.73\n",
      "Loss improved from 1676.73 to 1481.72\n",
      "Loss improved from 1481.72 to 802.22\n",
      "Loss improved from 802.22 to 733.97\n",
      "Loss improved from 733.97 to 542.07\n",
      "Loss improved from 542.07 to 259.07\n",
      "Loss improved from 259.07 to 15.13\n",
      "Loss improved from 15.13 to 11.45\n",
      "Loss improved from 11.45 to 10.99\n",
      "Loss improved from 10.99 to 9.84\n",
      "Loss improved from 9.84 to 5.98\n",
      "Loss improved from 5.98 to 4.79\n",
      "\n",
      "Best Loss: 4.79\n",
      "\n",
      "key:  weight\n",
      "tensor([[-0.1250,  0.8999,  0.1911],\n",
      "        [ 0.0995,  0.7631,  0.3453]])\n",
      "key:  bias\n",
      "tensor([-0.5509, -0.3800])\n"
     ]
    }
   ],
   "source": [
    "######################## PyTorch Implementation of Linear Regression with a Toy Problem #####################\n",
    "\n",
    "# Import different packages\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "print('PyTorch Version',torch.__version__)\n",
    "print('Numpy Version',np.__version__,'\\n')\n",
    "################################################################\n",
    "torch.manual_seed(0)   #You can use torch.manual_seed() to seed the RNG for all devices (both CPU and CUDA)\n",
    "random.seed(0)         #For custom operators, you might need to set python seed\n",
    "np.random.seed(0)      #If you or any of the libraries you are using rely on NumPy, you can seed the global NumPy RNG\n",
    "################################################################\n",
    "\n",
    "# Utility function to train the model\n",
    "def fit(num_epochs, model, loss_fn, opt, train_dl):\n",
    "    \n",
    "    best_loss = np.Inf\n",
    "    # Repeat for given number of epochs\n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        # Train with batches of data\n",
    "        for xb,yb in train_dl:\n",
    "            \n",
    "            # 1. Generate predictions\n",
    "            pred = model(xb)\n",
    "            \n",
    "            # 2. Calculate loss\n",
    "            loss = loss_fn(pred, yb)\n",
    "            \n",
    "            # 3. Save best model based on loss\n",
    "            if loss.detach().numpy() < best_loss:\n",
    "                print('Loss improved from {:.2f} to {:.2f}'.format(best_loss,loss.detach().numpy()))\n",
    "                best_loss = loss.detach().numpy()\n",
    "                \n",
    "                torch.save(model, 'best_linreg_model.pth')\n",
    "            \n",
    "            # 4. Compute gradients\n",
    "            loss.backward()\n",
    "            \n",
    "            # 5. Update parameters using gradients\n",
    "            opt.step()\n",
    "            \n",
    "            # 6. Reset the gradients to zero\n",
    "            opt.zero_grad()\n",
    "        \n",
    "        # Print the progress\n",
    "        if (epoch+1) == num_epochs:\n",
    "            #print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))\n",
    "            print('\\nBest Loss: {:.2f}\\n'.format(best_loss))\n",
    "            model = torch.load('best_linreg_model.pth')\n",
    "            \n",
    "            for key in model.state_dict():\n",
    "                print('key: ', key)\n",
    "                param = model.state_dict()[key]\n",
    "                print(param)\n",
    "\n",
    "                \n",
    "######################################################################            \n",
    "# Input (temp, rainfall, humidity)\n",
    "inputs = np.array([[73, 67, 43], \n",
    "                   [91, 88, 64], \n",
    "                   [87, 134, 58], \n",
    "                   [102, 43, 37], \n",
    "                   [69, 96, 70]], dtype='float32')\n",
    "\n",
    "# Targets (apples, oranges)\n",
    "targets = np.array([[56, 70], \n",
    "                    [81, 101], \n",
    "                    [119, 133], \n",
    "                    [22, 37], \n",
    "                    [103, 119]], dtype='float32')\n",
    "\n",
    "# Convert inputs and targets to tensors\n",
    "inputs = torch.from_numpy(inputs)\n",
    "targets = torch.from_numpy(targets)\n",
    "print(inputs)\n",
    "print(targets,'\\n')\n",
    "\n",
    "\n",
    "#########################################################################\n",
    "# Define dataset\n",
    "train_ds = TensorDataset(inputs, targets)\n",
    "train_ds[0:3]\n",
    "\n",
    "# Define data loader\n",
    "batch_size = 3  # should be << number of observations\n",
    "train_dl = DataLoader(train_ds, batch_size, shuffle=True)\n",
    "\n",
    "for xb, yb in train_dl:\n",
    "    print(xb)\n",
    "    print(yb,'\\n')\n",
    "    break\n",
    "\n",
    "    \n",
    "###########################################################################\n",
    "# Define model\n",
    "model = nn.Linear(3, 2)\n",
    "print(model.weight)\n",
    "print(model.bias,'\\n')\n",
    "\n",
    "# Define loss function\n",
    "loss_fn = F.mse_loss\n",
    "\n",
    "# SGD Optimizer\n",
    "opt = torch.optim.SGD(model.parameters(), lr=1e-5)\n",
    "\n",
    "fit(100, model, loss_fn, opt, train_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "duplicate-evanescence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 58.8338,  72.8634],\n",
       "        [ 79.4949,  97.9324],\n",
       "        [120.2446, 130.5661],\n",
       "        [ 32.4629,  55.3621],\n",
       "        [ 90.5918, 103.9203]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate predictions\n",
    "model = torch.load('best_linreg_model.pth')\n",
    "model.eval()\n",
    "\n",
    "preds = model(inputs)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "colored-advantage",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 56.,  70.],\n",
       "        [ 81., 101.],\n",
       "        [119., 133.],\n",
       "        [ 22.,  37.],\n",
       "        [103., 119.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Actual outputs\n",
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "complimentary-bedroom",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[55.1752, 70.3553]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inferencing a given input\n",
    "model(torch.tensor([[75, 63, 44.]]))  #testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "interested-success",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key:  weight\n",
      "tensor([[-0.1250,  0.8999,  0.1911],\n",
      "        [ 0.0995,  0.7631,  0.3453]])\n",
      "key:  bias\n",
      "tensor([-0.5509, -0.3800])\n"
     ]
    }
   ],
   "source": [
    "# Verify the best model's weights and bias\n",
    "for key in model.state_dict():\n",
    "    print('key: ', key)\n",
    "    param = model.state_dict()[key]\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wrong-circuit",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
